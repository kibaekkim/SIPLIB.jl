In this section, we explain general description of SIP. This includes formal mathematical formulation, existing general solution methods to solve the SIPs, and currently available software libraries.
\subsection{Formulation}
In this subsection, we introduce the form of SIP of interest. The notations and dimensional information are summarized in Table \ref{notation:SIP}. We are interested in finding solution for two-stage SIP of the form: 
\begin{align}
z:=\min_{x\in X}{\left\{c^\top x + \mathcal{Q}(x):\ Ax\ge b\right\}}, \label{eq:SIP_1}
\end{align}
where $\mathcal{Q}(x):=\EE_{\pmb{\xi}}\left[ \phi\left( h(\pmb{\xi})-T(\pmb{\xi})x \right) \right]$ is the recourse function associated with the random variable (r.v.) $\pmb{\xi}$. We assume that $\pmb{\xi}$ follows a known discrete probability distribution with the finite realizations, called \textit{scenarios}, $\xi_1,\cdots,\xi_r$ and respective nonnegative probabilities $\PP(1),\cdots,\PP(r)$, i.e., $\PP(s)\equiv\PP[\pmb{\xi}=\xi_s]$ for $s\in\mathcal{S}:=\{1,\ldots,r\}$. When the distribution is continuous, we assume that we can reasonably approximate it by a suitably discretized distribution. The real-valued map $\phi_{\xi_s}:\mathbb{R}^{m_2}\to\mathbb{R}$ is the optimal value of the second-stage problem defined by
\begin{align}
\phi_{\xi_s}(t):=\min_{y_s\in Y}\left\{ q(\xi_s)^\top y_s:\ W(\xi_s)y_s \ge t \right\},\ t\in\mathbb{R}^{m_2},
\end{align}
where $\xi_s$ is an arbitrarily realized scenario.
The sets $X\subseteq \mathbb{R}^{n_1}$ and $Y\subseteq\mathbb{R}^{n_2}$ represent integer or binary restrictions on a subset of the decision variables $x$ and $y_s$, respectively. 
The first-stage problem data comprise $A$, $b$, and $c$. The second-stage data are given by $T(\xi_s)$, $W(\xi_s)$, $h(\xi_s)$, and $q(\xi_s)$ (for dimensional information refer to Table \ref{notation:SIP}). Hereinafter, we use the simplified notations $(T_s,W_s,h_s,q_s)$.
The SIP (\ref{eq:SIP_1}) can be rewritten in the extensive form
\begin{subequations}\label{sip:ef}
\begin{align}
z=\min_{x,y_s}\ &c^{\top}x + \sum_{s=1}^{r}\PP(s) (q_j^{\top}y_s), \label{ef:obj}\\ 
\mathrm{s.t.}\ &Ax\ge b,  \label{ef:b}\\
	&T_s x+W_s y_s\ge h_s,\quad\forall s\in\{1,\ldots,r\}, \label{ef:c} \\
	&x\in X, \label{ef:d} \\
	&y_s \in Y,\quad\forall s\in\{1,\ldots,r\}. \label{ef:e}
\end{align}
\end{subequations}

%The nonanticipativity constraints in (\ref{eq:SIP_2-2}) stand for the equations $x_1=x_r$ and $x_j=x_{j-1}$ for $j=2,\ldots,r$, and $H_j$ is a suitable $rn_1\times n_1$ matrix. We assume that SIP does not necessarily have relatively complete recourse. We recall that without this property there can exist an $\hat{x}\in X$ satisfying $A\hat{x}\ge b$ for which there does not exist a recourse $y\in\mathbb{R}^{m_2}$ satisfying $(\hat{x},y)\in G_j$ for some $j$. In other words, not every choice of the first-stage variables is guaranteed to have feasible recourse for all scenarios.

\begin{table}[H]
	\caption{Summary of notations in SIP formulation}
	\label{notation:SIP}
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{ll}
			\toprule
			\multicolumn{2}{l}{\textbf{Sets:}} \\ 
			$X\subseteq\mathbb{R}^{n_1}$	& first-stage polyhedral set (continuous, integer, binary)\\
			$Y\subseteq\mathbb{R}^{n_2}$	& second-stage polyhedral set (continuous, integer, binary)\\ 
			$\mathcal{S}=\{1,\ldots,r\}$	& index set of realizable scenarios \\ \midrule
			%$G_j$	& scenario feasibility set\\ \midrule
			\multicolumn{2}{l}{\textbf{Scalas:}} \\ 
			$\pmb{\xi}$	& r.v. denoting scenario that realizes by one of the set $\{\xi_1,\cdots,\xi_r\}$ 	\\			
			$z\in\mathbb{R}$ & optimal objective value of the SIP \\ 
			$r\in\mathbb{N}$	& number of scenarios	\\	
			$s\in\mathcal{S}$	& index denoting scenario	\\
			$\PP(s)\in[0,1]$ & probability that scenario $s$ happens, i.e., $\PP(s)\equiv\PP[\pmb{\xi}=\xi_s]$ \\ \midrule
			\multicolumn{2}{l}{\textbf{Vectors:}} \\  
			$x\in\mathbb{R}^{n_1}$	& first-stage decision vector	\\
			$c\in \mathbb{R}^{n_1}$	& first-stage cost vector\\
			$b\in\mathbb{R}^{m_1}$	& first-stage RHS vector\\
			$y_s\in\mathbb{R}^{n_2}$	& second-stage decision vector under scenario $\xi_s$	\\
			$q_s\equiv q(\xi_s)\in\mathbb{R}^{n_2}$	& second-stage cost vector \\
			$h_s\equiv h(\xi_s)\in\mathbb{R}^{m_2}$	& second-stage RHS vector\\ \midrule
			%$\mathbf{0}\in\mathbb{R}^{rn_1}$	& vector filled with zeros \\ \midrule
			\multicolumn{2}{l}{\textbf{Matrices:}} \\  
			$A\in\mathbb{R}^{m_1\times n_1}$	& first-stage constraint matrix corresponds to decision vector $x$\\
			$W_s\equiv W(\xi_s)\in\mathbb{R}^{m_2\times n_2}$	& second-stage constraint matrix corresponds to decision vector $y_s$\\
			$T_s\equiv T(\xi_s)\in\mathbb{R}^{m_2\times n_1}$	& second-stage constraint matrix corresponds to decision vector $x$\\ \midrule
			%$H_j\equiv H(\xi_j)\in\mathbb{R}^{rm_1\times n_1}$	&	nonanticipativity constraints matrix \\ \midrule
			\multicolumn{2}{l}{\textbf{Functions:}} \\
			$\phi_{\xi_s}:\mathbb{R}^{m_2}\to\mathbb{R}$	& second stage program optimal value under the realization of scenario $\xi_s$	\\
			$\mathcal{Q}:\mathbb{R}^{n_1}\to\mathbb{R}$	& recourse function (the expectation of $\phi\left( h(\pmb{\xi})-T(\pmb{\xi})x \right)$ over the r.v. $\pmb{\xi}$) 	\\
			\bottomrule
		\end{tabular}
	}
\end{table} 

\subsection{Solution methods}
Assuming finite and discrete distribution, we can always formulate SIP in the full deterministic equivalent MIP or extensive form as in Equations (\ref{ef:obj})-(\ref{ef:e}).  %much of the solution methods in SIP is studied to resolve the difficulty of optimizing the form in Equation \ref{eq:SIP_1}, 
%Much of the solution methods in SIP is studied to resolve the difficulty of optimizing the extensive form. %That is, the sum of the first-stage costs and the expected costs in the second-stage. 
Most methods in SIP assume that a single scenario evaluation is somehow tractable. With a number of realizations, however, the extensive form becomes a quite large. Solving the MIP without exploiting the special structure can easily go with inefficiency. In this section, we introduce representative approaches to resolve the difficulties in SIP considering many scenarios.
\kk{A deterministic equivalent form needs to be provided.} \yoc{Extensive form is given by Equations (\ref{ef:obj})-(\ref{ef:e}). I modify some sentences here towards including the term ``extensive form."}

\subsubsection{Stage-wise decomposition}
This type of algorithms exploit the natural viewpoint of optimizing the objective function in Equation (\ref{eq:SIP_1}) over the set of feasible first-stage decisions. The method used most frequently are based on building an outer linearization of the recourse cost function and a solution of the first-stage problem plus this linearization. This cutting plane technique is called the \textit{L-shaped method} or \textit{Benders decomposition} \cite{B1962}, from which the variants of stage-wise decomposition methods are derived.

For SIP with pure binary first-stage variables and mixed integer second-stage, the integer L-shaped method \cite{LL1993} approximates the second-stage recourse function by linear cuts that are exact at the binary solution where the cut is generated and are under-estimates at other binary solutions. 

For SIP where the first-stage variables are not necessarily binary, dual functions from the second-stage integer program can be used to construct cuts to build the approximation of $\mathcal{Q}(x)$ \cite{CT1998}.  %In each iterations, the algorithm finds a tractable approximation of the recourse function $\mathcal{Q}(x)$, say $\hat{\mathcal{Q}}(\hat{x})$. Given that, the objcetive function $c^\top x + \hat{\mathcal{Q}}(x)$ is optimized with respect to the first-stage variables to provide a lower bound on the true optimal.

\subsubsection{Scenario-wise decomposition}
In this type algorithms, we first introduce the copies of the first stage variables into the second stage. Then, the extensive form in (\ref{sip:ef}) is changed as below.
\begin{subequations}
	\begin{align}
	z=\min_{x_s,y_s}\ &\sum_{s=1}^{r}p_s\left(c^{\top}x_s+q_s^{\top}y_s\right)	\label{eq:SIP_2-1}\\ 
	\mathrm{s.t.}\ &\sum_{s=1}^{r}H_s x_s=0 \label{eq:SIP_2-2} \\
	\ &(x_s,y_s)\in G_s,\quad \forall s\in\{1,\ldots,r\},	\label{eq:SIP_2-3}
	\end{align}
\end{subequations}
where the scenario feasibility set $G_s$ is defined as
\begin{align}
G_s:=\left\{ (x_s,y_s): \ Ax_s\ge b,\  T_s x_s+W_s y_s\ge h_s,\ (x_s,y_s)\in X\times Y  \right\}. \label{eq:SIP_2-4}
\end{align}
The newly added constraints (\ref{eq:SIP_2-2}) (called \textit{nonanticipativity}) guarantee $x_1=x_r$ and $x_s=x_{s-1}$ for $s=2,\ldots,r$ with a suitable $rn_1\times n_1$ coefficient matrix $H_s$. This can be presented in another expression other than the one above that Car\o e and Schultz \cite{CS1999} proposed.
%We assume that SIP does not necessarily have relatively complete recourse. We recall that without this property there can exist an $\hat{x}\in X$ satisfying $A\hat{x}\ge b$ for which there does not exist a recourse $y\in\mathbb{R}^{m_2}$ satisfying $(\hat{x},y)\in G_s$ for some $s$. In other words, not every choice of the first-stage variables is guaranteed to have feasible recourse for all scenarios.

Two representative scenario-wise decomposition algorithms are Dual Decomposition (DD, \cite{CS1999}) and Progressive Hedging (PH, \cite{RW1991}). The main idea of DD algorithm is to relax the nonanticipativity constraints using Lagrange multipliers and then to restore the nonanticipativity. Given set of multipliers, the problem is separable by scenarios hence the associated dual function can be optimized scenario-wise independently. Due to the nonconvexities, there can exist a duality gap between relaxed problem and the original problem so the optimality needs to be attained branch-and-bound scheme.

PH algorithm is developed by Rockafellar and Wets motivated by augmented Lagrangian theory. To briefly introduce the idea of PH, we define the following terms for solution systems.
\begin{itemize}
	\item admissible: a solution that satisfies the constraints for all scenarios
	\item implementable (or nonanticipative): a solution in which the first stage decisions are indifferent over all scenarios
	\item feasible: a solution that is both admissible and implementable
\end{itemize}
The basic idea of PH can be summarized by the following procedure \cite{book:pyomo}.
\begin{enumerate}
	\item For each scenario $s$, solutions are obtained for the single-scenario problem of minimizing, subject to the problem constraints, the formulation (\ref{eq:SIP_2-1})-(\ref{eq:SIP_2-3}), and (\ref{eq:SIP_2-4}).
	\item The variable values for an implementable---but likely not admissible---solution are obtained by averaging over all scenarios at a scenario tree node.
	\item For each scenario $s$, solutions are obtained for the problem of minimizing, subject to the problem constraints, the deterministic solution as in Step 1. plus terms that penalize the lack of implementability using a subgradient estimator for the nonanticipativity constraints and a squared penalty term.
	\item If the solutions have not converged sufficiently and the allocated compute time is not exceeded, goto Step 2.
	\item Post-process, if needed, to produce a fully admissible and implementable solution.
\end{enumerate}

One advantage of scenario-wise decomposition over the stage-wise methods is their ability to relieve the computational burden associated with large number of scenarios by decomposing the problem by scenario and solving the descendant subproblems in parallel manners.

\subsection{Software libraries}
Assuming discrete distribution, all SIP can be represented by any algebraic modeling languages and then solved by any available MIP solvers. However, such manual implementation without exploiting structural characteristics in SIP can often result in inefficient computation and unnecessary memory allocation. In this subsection, we introduce some open-source software libraries dedicated to SIP.

\subsubsection{Modeling language}
We introduce two relatively new algebraic SIP modeling languages which are compatible with general purpose high-level programming languages \julia\ and \python. Both modeling libraries allows non-specialists to easily write mathematical model on the computing environment.

\structjump\ is a \julia\ package provides a parallel algebraic modeling framework for block-structured optimization models. \structjump\ is an extension of the \jump\ modeling package (\julia\ for Mathematical Optimization), which is faster than any other modeling tools. \structjump\ enables \jump\ to express the structure of problems and efficiently interface with structure-exploiting solvers. It also works in parallel (distributed memory), and thus allows the specification of much larger (structured) problems than \jump\ can handle. 

\pysp\ is an extension of a \python-based algebraic modeling package \pyomo. To formulate a
stochastic program in \pysp, the user specifies both the deterministic base model and
the scenario tree with associated uncertain parameters in \pyomo. Given these two models, \pysp\ can directly solve the stochastic program using two ways: extensive form and PH algorithm. %One advantage of \pysp\ is this integrated working environment combining model and solver. Hence, provide completely generic and highly configurable solver implementations.

\subsubsection{Solver}
We introduce two popular open source solver packages: \dsp\ and \pysp. 
 
\dsp\ is an open-source SIP solver implemented in \cpp. \dsp\ reads \smps\ files as input and provides three ways to solve a SIP instance.
\begin{itemize}
	\item Invoking standard MIP solver to solve the extensive form SIP
	\item L-shape method (Benders decomposition)
	\item Dual Decomposition algorithm
\end{itemize}
\dsp\ provides parallel implementations for the two decomposition-based algorithms, which allows users fully exploit computing clusters and multi-core processors. \dsp\ also provides \julia\ interface to improve its usability.

\pysp\ is a stochastic programming extension to \pyomo, a \python-based open source software package that supports variants of mathematical optimization. \pysp\ enables the expression of stochastic programming problems as extensive form. \pysp\ provides two ways to solve the instance. 
\begin{itemize}
	\item Invoking standard MIP solver to solve the extensive form SIP
	\item Progressive Hedging algorithm
\end{itemize}
\pysp\ can also solve the extensive form SIP invoking standard MIP solver. To solve more complex and large-scale SIP, \pysp\ implements PH algorithm, which provides an effective heuristic for approximating general multi-stage SIP.



